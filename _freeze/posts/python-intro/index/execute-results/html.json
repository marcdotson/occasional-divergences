{
  "hash": "71e7f2c25649ce4b1f09f714fc069270",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"An introduction to Python for R users\"\nauthor: \"Marc Dotson\"\ndate: \"2025-06-13\"\ndescription: |\n  This introduction to Python assumes you know R, which is used as an analogy to explain Python for data analysis.\ncategories:\n  - python\n  - r\n  - quarto\n  - pymc\nimage: figures/python.png\nslug: python-intro\nhighlight-style: arrow\n---\n\n::: {.cell}\n\n:::\n\n\n\nIn classes and workshops over many years, I've taught data analytics using R. But in my new position, I teach data analytics using Python. This introduction to Python is for R users---primarily me, though I hope it proves useful to others as well.\n\nThere are incredible resources in this space, and I've drawn liberally from a number of them. As an overall introduction to Python, [*Python for Data Analysis*](https://wesmckinney.com/book/) is a go-to resource and the spiritual equivalent of [*R for Data Science*](https://r4ds.hadley.nz). I also really appreciate the work in [*Python and R for the Modern Data Scientist*](https://www.amazon.com/Python-Modern-Data-Scientist-Worlds/dp/1492093408), especially for the authors' clear espousing that this isn't an either/or situation---you can (and arguably *should*) use Python and R as complements.\n\n![](figures/python-r.png){width=60% fig-align=\"center\"}\n\nI am especially indebted to Emily Riederer's blog series beginning with [Python Rgonomics](https://emilyriederer.netlify.app/post/py-rgo-2025/) and subscribe to her philosophy of using tools in Python that are genuinely \"Pythonic\" while being consistent with the workflow and ergonomics of the best R has to offer. I am also grateful to extra help from [posit::conf](https://posit.co/conference/) workshop instructors and colleagues in my new position at [Utah State University](https://huntsman.usu.edu/dais/). Additional resources will be provided where relevant in each section.\n\n## Different mindsets\n\nWhen you start working with Python, it's essential that you approach it with the right mindset. R is a specialized language developed by statisticians for data analysis. Python is a *big* tent, a general programming language developed by computer scientists for many things, with only a small portion of it dedicated to data analysis.\n\nTo summarize some key differences:\n\n| Python | R | \n| --- | --- | \n| General language | Specialized language | \n| Developed by computer scientists | Developed by statisticians | \n| Object-oriented programming | Functional programming | \n| Obsessed with efficiency | Lazy about efficiency | \n| Obsessed with namespacing | Lazy about namespacing | \n| Small, medium, and large data | Small and medium data | \n| Machine learning and deep learning | Data wrangling and visualization | \n| Spacing is part of the syntax | Spacing is for convenience | \n| Indices start with 0 | Indices start with 1 | \n| No single authority | Dominated by Posit | \n| Jupyter Notebooks | R Markdown and Quarto | \n| Inconsistent (i.e., no tidyverse) | Consistency in the tidyverse | \n| \"Pythonistas\" and \"Pythonic\" code | \"R Users\" and \"Tidy\" code |\n\nWhile these are broad strokes and not 100% accurate in every case, they help provide some high-level context for how the two languages deviate in their approaches to common problems.\n\n## Functions, methods, and attributes\n\nWith the right mindset, it's easier to understand some of the things that Python is obsessed with that R simply isn't. The most important difference is that Python is an object-oriented programming language while R is all about functional programming. While *everything* in R is a function (for a typical user), using Python requires frequently keeping track of the difference between functions, methods, and attributes.\n\nFunctions in Python and R are equivalent, although functions in Python are typically namespaced with the library name or alias like `library.function()`. Note that we can, but often don't, similarly namespace R functions with `package::function()`. Methods are object-specific functions. In other words, methods are functions nested within object types and are namespaced with an object name of the given type as in `object.method()`. While it's possible to import a specific function such that we can call it without referencing it's library name or alias, we can never call a method without reference to an object name of the necessary type. In other words, we may see a `function()` like in R but we will always see a `.method()` with an object. One more set of definitions---just like packages in Python are typically referred to as libraries, function (and method) arguments are referred to as parameters.\n\nAttributes are object-specific features and are, like methods, namespaced with an object name of the give type as in `object.attribute`, but without any parentheses. For example, the dimensions of a NumPy array could be referenced with `array.size` while the equivalent in base R would be a function like `dim(array)`.\n\n## Get started\n\nThe first hurdle as we work to apply our new mindset is simply getting Python and our project environment installed. This is a big departure from what we're used to in R, where there is one way to install R and we usually ignore our project environment, let alone [make it reproducible](https://occasionaldivergences.com/posts/rep-env/). Remember, Python is a *big* tent with lots of uses and, unsurprisingly, lots of ways to do everything I'm covering. However, from the perspective of someone coming from R and with a focus on data analytics, I recommend the following.\n\nWhile I started using [pyenv](https://github.com/pyenv/pyenv) and [venv](https://docs.python.org/3/library/venv.html) for managing Python versions and libraries, respectively, there's a new(er) kid on the block that has been receiving lots of attention: [uv](https://docs.astral.sh/uv/), a single unified tool for managing Python project environments. (As a bellweather, [{reticulate}](https://posit.co/blog/reticulate-1-41/) and [Positron](https://positron.posit.co) now use uv.) Get started by [installing uv](https://docs.astral.sh/uv/getting-started/installation/) via the command line.\n\n::: {.callout-note title=\"The Command Line\"}\nUsing the command line (i.e., terminal or shell) isn't as common for R users who are comfortable with a dedicated console for running code. Be patient, take your time, and follow any instructions from a trusted source closely. A few things to help:\n\n- The command line is the programming interface into your OS itself. You don't have to know everything about it to follow instructions.\n- Instructions can be different based on the *type* of command line. If you're on a Mac that's running macOS Catalina 10.15.7 or later, the terminal is Zsh. If you're using Linux, the shell is Bash (and you probably already know that). And if you're using Windows you're working with PowerShell.\n:::\n\n### Install Python\n\nUnlike your experience with R, Python comes pre-installed on some operating systems. This version *should not be used* by anyone except the OS itself. For this and other reasons, you'll need the ability to maintain multiple versions of Python on the same computer. Once you have uv installed, it's easy to install and manage Python versions.\n\n- To install the latest stable release of Python, on the command line, run `uv python install`. To see which versions of Python you have installed, run `uv python find`; none of these will be the off-limits OS version.\n- You can also install specific versions of Python, such as `uv python install 3.13.4` to install Python 3.13.4. To view Python versions that are available to install, run `uv python list`.\n\n::: {.callout-tip title=\"Positron IDE\"}\nAs you well know, an integrated development environment (IDE), outside of an open source language, is arguably your most important tool as a data analyst. There are many options, but I recommend [Positron](https://positron.posit.co), a next-generation data science IDE. Built by Posit on VS Code's [open source core](https://github.com/microsoft/vscode), Positron combines the multilingual extensibility of [VS Code](https://code.visualstudio.com/) with essential data tools common to language-specific IDEs.\n\nIf RStudio is too specific and VS Code is too general, you may find that [Positron is just right](https://occasionaldivergences.com/posts/positron-intro/) and becomes your only IDE for both Python and R. And unless you're comfortable navigating between directories using the command line, Positron's built-in terminal will be tied to the working directory you have opened in the IDE.\n:::\n\n### Initialize a project environment\n\nA project environment is composed of the language(s) and libraries (including the dependencies) used for a given project. What makes a project environment reproducible is keeping track of which *version* of the language(s) and the libraries we're using for a given project so that it can be easily reproduced on another machine by you (including future you) or someone else.\n\n- After navigating to a project working directory, run `uv init` to initialize a project environment. This creates a `pyproject.toml` file with metadata about the project and a hidden `.python-version` file that specifies the default version of Python for the project. (It also creates `main.py` and `README.md` files that you can use or delete.)\n- With the project environment initialized, you can install libraries. For example, to install the Polars library, run `uv add polars`. This installs Polars, and any dependencies, and creates both a `uv.lock` file that keeps track of the versions of the libraries you've installed and a hidden `.venv` reproducible (or *virtual*, hence the \"v\" in venv) environment folder that serves as the project library.\n\nJust like with R, all Python libraries are installed in a single, global library on your computer known as the *system library*. The fact that we have a *project library* highlights an important feature of making project environments reproducible: Each project will have its own project library and thus be *isolated*. If two projects use different versions of the same package, they won't conflict with each other because they'll each have their own project library. (Well, not *exactly*. Python employs a global cache to avoid having to install the same version of a given library more than once. The project library will reference the global cache.) Whenever you install new libraries, the `uv.lock` file is automatically updated. And if you're starting with an existing project, run `uv run` for the libraries included in `uv.lock` to be automatically installed.\n\nIt might seem like a lot just to get started, but it's something [we should be doing in R](https://occasionaldivergences.com/posts/rep-env/) as well. Along with a project's code, all someone would need is the `pyproject.toml`, `.python-version`, and `uv.lock` files to reproduce your code, including the project environment. Well, assuming they're also using uv to manage their project environments. If they're using another tool to install libraries instead (yes, there are *many* ways to install libraries in Python), they will likely need a `requirements.txt` file or a `pylock.toml` file to reproduce the project environment, which you can create with `uv export --format requirements-txt` or `uv export -o pylock.toml`, respectively.\n\n## Data wrangling\n\nWhatever the language, the most common task we have for any data analysis is data wrangling (i.e., cleaning, munging, etc.). The [NumPy](https://numpy.org) library is more or less equivalent to what we see in base R, introducing arrays and efficient computation across arrays---but, perhaps surprisingly, not data frames. Data frames (or DataFrames as they are referred to in Python) came later with [pandas](https://pandas.pydata.org) (short for \"panel data\"). Still the most popular library for data wrangling in Python, pandas is built to supplement NumPy, with all of the syntax baggage. However, growing in popularity is [Polars](https://pola.rs) (an anagram of the query language it uses, OLAP, and the language it's built in, Rust or rs). Polars is something of an answer to pandas problems. Actually, free from any Python code at all (yes, you can [use it in R](https://github.com/pola-rs/r-polars)), it offers a glimpse at what the polyglot future might look like.\n\nMy take is that Polars provides a more self-consistent data wrangling experience than pandas, reversing the trend that many experience when they come to Polars for the speed and stay for the syntax. To illustrate the tidyverse spiritual connections, if not the deeper roots in SQL syntax, there are a number of great side-by-side comparisons of [Polars and {dplyr}](https://blog.tidy-intelligence.com/posts/dplyr-vs-polars/). I'll illustrate a few common tasks in both Polars and {dplyr} and point out the differences to be mindful of.\n\n### Import data\n\nLibraries and modules (a kind of sub-library) are imported with commonly accepted aliases in order to shorten the namespace reference. For example, the Polars alias convention is `pl`. We're also importing the os library, which needs no alias, to write out a relative file path that will work for any user or operating system that has the same relative directory structure; a \"Pythonic\" version of {here}.\n\nNote the difference between the `pl.read_csv()` function and the `.shape` and `.columns` attributes.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport polars as pl\nimport os\n\ncustomer_data = pl.read_csv(os.path.join('data', 'customer_data.csv'))\ncustomer_data.shape\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(10531, 13)\n```\n\n\n:::\n\n```{.python .cell-code}\ncustomer_data.columns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['customer_id', 'birth_year', 'gender', 'income', 'credit', 'married', 'college_degree', 'region', 'state', 'star_rating', 'review_time', 'review_title', 'review_text']\n```\n\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ncustomer_data <- read_csv(here::here(\"posts\", \"python-intro\", \"data\", \"customer_data.csv\"))\nglimpse(customer_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 10,531\nColumns: 13\n$ customer_id    <dbl> 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1…\n$ birth_year     <dbl> 1971, 1970, 1988, 1984, 1987, 1994, 1968, 1994, 1958, 1…\n$ gender         <chr> \"Female\", \"Female\", \"Male\", \"Other\", \"Male\", \"Male\", \"M…\n$ income         <dbl> 73000, 31000, 35000, 64000, 58000, 164000, 39000, 69000…\n$ credit         <dbl> 742.0827, 749.3514, 542.2399, 573.9358, 644.2439, 553.6…\n$ married        <chr> \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\"…\n$ college_degree <chr> \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\"…\n$ region         <chr> \"South\", \"West\", \"South\", \"Midwest\", \"West\", \"Midwest\",…\n$ state          <chr> \"DC\", \"WA\", \"AR\", \"MN\", \"HI\", \"MN\", \"MN\", \"KY\", \"NM\", \"…\n$ star_rating    <dbl> 4, NA, NA, NA, 5, 2, NA, 5, NA, 5, NA, 5, NA, NA, NA, N…\n$ review_time    <chr> \"06 11, 2015\", NA, NA, NA, \"03 25, 2008\", \"06 7, 2013\",…\n$ review_title   <chr> \"Four Stars\", NA, NA, NA, \"Great Product!!\", \"Not at al…\n$ review_text    <chr> \"everything's fine\", NA, NA, NA, \"I looked all over the…\n```\n\n\n:::\n:::\n\n\n:::\n\n### Filter observations\n\nPolars DataFrames have methods that are similar to {dplyr} (e.g., `.filter()` and `filter()`). DataFrames are composed of columns called Series (equivalent to R's vectors). Note that unlike pandas DataFrames, Polars DataFrames don't have a row index.\n\nIn pandas, we would need to reference column names with `data['column_name']` (like base R's `data$column_name` or `data[\"column_name\"]`), but Polars allows for `pl.col('column_name')`. Yes, we use quotation marks for every column name. The `pl.col()` expression offers a helper-function-like consistency.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncustomer_data.filter(pl.col('gender') == 'Female', pl.col('income') > 70000)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3_970, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>birth_year</th><th>gender</th><th>income</th><th>credit</th><th>married</th><th>college_degree</th><th>region</th><th>state</th><th>star_rating</th><th>review_time</th><th>review_title</th><th>review_text</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1001</td><td>1971</td><td>&quot;Female&quot;</td><td>73000</td><td>742.082667</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;DC&quot;</td><td>4</td><td>&quot;06 11, 2015&quot;</td><td>&quot;Four Stars&quot;</td><td>&quot;everything&#x27;s fine&quot;</td></tr><tr><td>1010</td><td>1994</td><td>&quot;Female&quot;</td><td>77000</td><td>605.157869</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;VT&quot;</td><td>5</td><td>&quot;10 18, 2015&quot;</td><td>&quot;nice strong enough&quot;</td><td>&quot;Yeah&quot;</td></tr><tr><td>1012</td><td>1953</td><td>&quot;Female&quot;</td><td>126000</td><td>672.59663</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;DC&quot;</td><td>5</td><td>&quot;01 6, 2015&quot;</td><td>&quot;Five Stars&quot;</td><td>&quot;easy setup&nbsp;&nbsp;works great&quot;</td></tr><tr><td>1013</td><td>1974</td><td>&quot;Female&quot;</td><td>197000</td><td>680.211781</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;UT&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1022</td><td>1979</td><td>&quot;Female&quot;</td><td>155000</td><td>804.896188</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;UT&quot;</td><td>5</td><td>&quot;04 22, 2017&quot;</td><td>&quot;Yak Attack is great!&quot;</td><td>&quot;Very simple to use. Nice acces…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>11515</td><td>1969</td><td>&quot;Female&quot;</td><td>203000</td><td>645.425436</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;MA&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>11519</td><td>1977</td><td>&quot;Female&quot;</td><td>149000</td><td>676.361119</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;West&quot;</td><td>&quot;UT&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>11524</td><td>1994</td><td>&quot;Female&quot;</td><td>114000</td><td>644.463202</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;AL&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>11526</td><td>1987</td><td>&quot;Female&quot;</td><td>109000</td><td>611.095352</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;MS&quot;</td><td>4</td><td>&quot;04 22, 2016&quot;</td><td>&quot;Overall - A good deal&quot;</td><td>&quot;Not the highest quality in the…</td></tr><tr><td>11529</td><td>1966</td><td>&quot;Female&quot;</td><td>112000</td><td>820.539578</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;NJ&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(customer_data, gender == \"Female\", income > 70000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3,970 × 13\n   customer_id birth_year gender income credit married college_degree region   \n         <dbl>      <dbl> <chr>   <dbl>  <dbl> <chr>   <chr>          <chr>    \n 1        1001       1971 Female  73000   742. No      No             South    \n 2        1010       1994 Female  77000   605. Yes     No             Northeast\n 3        1012       1953 Female 126000   673. Yes     No             South    \n 4        1013       1974 Female 197000   680. Yes     Yes            West     \n 5        1022       1979 Female 155000   805. No      Yes            West     \n 6        1023       1995 Female 137000   539. No      Yes            Northeast\n 7        1024       1974 Female 285000   685. Yes     Yes            Midwest  \n 8        1028       1980 Female  87000   715. No      No             West     \n 9        1030       1969 Female 163000   636. Yes     Yes            West     \n10        1036       1978 Female 227000   614. Yes     Yes            Northeast\n# ℹ 3,960 more rows\n# ℹ 5 more variables: state <chr>, star_rating <dbl>, review_time <chr>,\n#   review_title <chr>, review_text <chr>\n```\n\n\n:::\n:::\n\n\n:::\n\n### Slice observations\n\nNote that Python is zero-indexed. This is probably the most problematic (and very computer science-based) difference and why it's nice to avoid indexing if you can!\n\nRemember that function (and method) arguments are called parameters. Some parameters are positional that have to be, as the name suggests, specified in an *exact* position. Others are keyword or named parameters, which is commonplace in R. The positional parameters for Polars' `.slice()` method are the start index and the slice length.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncustomer_data.slice(0, 5)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>birth_year</th><th>gender</th><th>income</th><th>credit</th><th>married</th><th>college_degree</th><th>region</th><th>state</th><th>star_rating</th><th>review_time</th><th>review_title</th><th>review_text</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1001</td><td>1971</td><td>&quot;Female&quot;</td><td>73000</td><td>742.082667</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;DC&quot;</td><td>4</td><td>&quot;06 11, 2015&quot;</td><td>&quot;Four Stars&quot;</td><td>&quot;everything&#x27;s fine&quot;</td></tr><tr><td>1002</td><td>1970</td><td>&quot;Female&quot;</td><td>31000</td><td>749.351433</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;West&quot;</td><td>&quot;WA&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1003</td><td>1988</td><td>&quot;Male&quot;</td><td>35000</td><td>542.239859</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;AR&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1004</td><td>1984</td><td>&quot;Other&quot;</td><td>64000</td><td>573.935783</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Midwest&quot;</td><td>&quot;MN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1005</td><td>1987</td><td>&quot;Male&quot;</td><td>58000</td><td>644.243856</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;HI&quot;</td><td>5</td><td>&quot;03 25, 2008&quot;</td><td>&quot;Great Product!!&quot;</td><td>&quot;I looked all over the Internet…</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nslice(customer_data, 1:5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 13\n  customer_id birth_year gender income credit married college_degree region \n        <dbl>      <dbl> <chr>   <dbl>  <dbl> <chr>   <chr>          <chr>  \n1        1001       1971 Female  73000   742. No      No             South  \n2        1002       1970 Female  31000   749. Yes     No             West   \n3        1003       1988 Male    35000   542. No      No             South  \n4        1004       1984 Other   64000   574. Yes     Yes            Midwest\n5        1005       1987 Male    58000   644. No      Yes            West   \n# ℹ 5 more variables: state <chr>, star_rating <dbl>, review_time <chr>,\n#   review_title <chr>, review_text <chr>\n```\n\n\n:::\n:::\n\n\n:::\n\n### Sort observations\n\nIt can be strange at first, but namespacing is critical. Remember that a function is preceded by the library name or alias (e.g., `pl.col()`), unless you've imported the specific function (e.g., `from polars import col`), while a method is preceded by an object name of a certain type (e.g., `customer_data.sort()`). Since object types are tied to libraries, the chain back to its corresponding library is always present, explicitly for functions and implicitly for methods.\n\nNote that its `True` and `False`, not `TRUE` and `FALSE` or `true` and `false`.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncustomer_data.sort(pl.col('birth_year'), descending = True)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10_531, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>birth_year</th><th>gender</th><th>income</th><th>credit</th><th>married</th><th>college_degree</th><th>region</th><th>state</th><th>star_rating</th><th>review_time</th><th>review_title</th><th>review_text</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1026</td><td>1999</td><td>&quot;Male&quot;</td><td>66000</td><td>643.030421</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;AL&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1049</td><td>1999</td><td>&quot;Other&quot;</td><td>88000</td><td>630.037632</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;WA&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1092</td><td>1999</td><td>&quot;Other&quot;</td><td>77000</td><td>664.000947</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Midwest&quot;</td><td>&quot;MO&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1107</td><td>1999</td><td>&quot;Female&quot;</td><td>97000</td><td>579.437133</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;CO&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1113</td><td>1999</td><td>&quot;Male&quot;</td><td>190000</td><td>660.594015</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;PA&quot;</td><td>5</td><td>&quot;07 10, 2014&quot;</td><td>&quot;Five Stars&quot;</td><td>&quot;this is awesome&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>8277</td><td>1947</td><td>&quot;Male&quot;</td><td>92000</td><td>839.039929</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;West&quot;</td><td>&quot;OR&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>8525</td><td>1947</td><td>&quot;Female&quot;</td><td>170000</td><td>723.312232</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;CO&quot;</td><td>3</td><td>&quot;09 4, 2016&quot;</td><td>&quot;Knuckles are not hard and they…</td><td>&quot;Knuckles&nbsp;&nbsp;are not hard and the…</td></tr><tr><td>9437</td><td>1947</td><td>&quot;Female&quot;</td><td>95000</td><td>850.0</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;ID&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>10069</td><td>1947</td><td>&quot;Other&quot;</td><td>84000</td><td>742.581417</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;WY&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>9585</td><td>1939</td><td>&quot;Female&quot;</td><td>182000</td><td>850.0</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;PA&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\narrange(customer_data, desc(birth_year))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10,531 × 13\n   customer_id birth_year gender income credit married college_degree region   \n         <dbl>      <dbl> <chr>   <dbl>  <dbl> <chr>   <chr>          <chr>    \n 1        1026       1999 Male    66000   643. No      No             South    \n 2        1049       1999 Other   88000   630. No      Yes            West     \n 3        1092       1999 Other   77000   664. No      Yes            Midwest  \n 4        1107       1999 Female  97000   579. No      Yes            West     \n 5        1113       1999 Male   190000   661. Yes     Yes            Northeast\n 6        1126       1999 Female 121000   639. No      Yes            Midwest  \n 7        1132       1999 Male    53000   669. No      No             West     \n 8        1139       1999 Female 293000   659. Yes     Yes            Northeast\n 9        1143       1999 Female  74000   587. No      Yes            West     \n10        1147       1999 Other  109000   429. Yes     No             West     \n# ℹ 10,521 more rows\n# ℹ 5 more variables: state <chr>, star_rating <dbl>, review_time <chr>,\n#   review_title <chr>, review_text <chr>\n```\n\n\n:::\n:::\n\n\n:::\n\n### Select variables\n\nUsing single square brackets `[ ]` creates a list. This is similar to creating a vector in R with `c()`. A list is a fundamental Python object type and can be turned into a Series.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncustomer_data.select(pl.col(['region', 'review_text']))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10_531, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>region</th><th>review_text</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;South&quot;</td><td>&quot;everything&#x27;s fine&quot;</td></tr><tr><td>&quot;West&quot;</td><td>null</td></tr><tr><td>&quot;South&quot;</td><td>null</td></tr><tr><td>&quot;Midwest&quot;</td><td>null</td></tr><tr><td>&quot;West&quot;</td><td>&quot;I looked all over the Internet…</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Northeast&quot;</td><td>null</td></tr><tr><td>&quot;Northeast&quot;</td><td>null</td></tr><tr><td>&quot;Northeast&quot;</td><td>null</td></tr><tr><td>&quot;Midwest&quot;</td><td>null</td></tr><tr><td>&quot;West&quot;</td><td>&quot;Husband really appreciates the…</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(customer_data, region, review_text)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10,531 × 2\n   region    review_text                                                        \n   <chr>     <chr>                                                              \n 1 South     everything's fine                                                  \n 2 West      <NA>                                                               \n 3 South     <NA>                                                               \n 4 Midwest   <NA>                                                               \n 5 West      I looked all over the Internet to find a non-plastic water bottle.…\n 6 Midwest   I ordered these sweat pants for my 12-year old daughter to wear fo…\n 7 Midwest   <NA>                                                               \n 8 South     Super comfortable mini pack. Bought it for hiking..large enough to…\n 9 West      <NA>                                                               \n10 Northeast Yeah                                                               \n# ℹ 10,521 more rows\n```\n\n\n:::\n:::\n\n\n:::\n\n### Create new variables\n\nPolars is actually a query language, like SQL. So it's not surprising to see methods with names that more closely mirror queries, like the `.with_columns()` method.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncustomer_data.with_columns(income = pl.col('income') / 1000)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10_531, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>birth_year</th><th>gender</th><th>income</th><th>credit</th><th>married</th><th>college_degree</th><th>region</th><th>state</th><th>star_rating</th><th>review_time</th><th>review_title</th><th>review_text</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1001</td><td>1971</td><td>&quot;Female&quot;</td><td>73.0</td><td>742.082667</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;DC&quot;</td><td>4</td><td>&quot;06 11, 2015&quot;</td><td>&quot;Four Stars&quot;</td><td>&quot;everything&#x27;s fine&quot;</td></tr><tr><td>1002</td><td>1970</td><td>&quot;Female&quot;</td><td>31.0</td><td>749.351433</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;West&quot;</td><td>&quot;WA&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1003</td><td>1988</td><td>&quot;Male&quot;</td><td>35.0</td><td>542.239859</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;AR&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1004</td><td>1984</td><td>&quot;Other&quot;</td><td>64.0</td><td>573.935783</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Midwest&quot;</td><td>&quot;MN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>1005</td><td>1987</td><td>&quot;Male&quot;</td><td>58.0</td><td>644.243856</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;HI&quot;</td><td>5</td><td>&quot;03 25, 2008&quot;</td><td>&quot;Great Product!!&quot;</td><td>&quot;I looked all over the Internet…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>11527</td><td>1982</td><td>&quot;Other&quot;</td><td>169.0</td><td>603.366567</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;NY&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>11528</td><td>1986</td><td>&quot;Female&quot;</td><td>24.0</td><td>647.671383</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;RI&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>11529</td><td>1966</td><td>&quot;Female&quot;</td><td>112.0</td><td>820.539578</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;NJ&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>11530</td><td>1971</td><td>&quot;Male&quot;</td><td>234.0</td><td>790.440173</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Midwest&quot;</td><td>&quot;OH&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>11531</td><td>1990</td><td>&quot;Male&quot;</td><td>160.0</td><td>641.77857</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;MT&quot;</td><td>5</td><td>&quot;08 21, 2014&quot;</td><td>&quot;These are definitely one of th…</td><td>&quot;Husband really appreciates the…</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmutate(customer_data, income = income / 1000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10,531 × 13\n   customer_id birth_year gender income credit married college_degree region   \n         <dbl>      <dbl> <chr>   <dbl>  <dbl> <chr>   <chr>          <chr>    \n 1        1001       1971 Female     73   742. No      No             South    \n 2        1002       1970 Female     31   749. Yes     No             West     \n 3        1003       1988 Male       35   542. No      No             South    \n 4        1004       1984 Other      64   574. Yes     Yes            Midwest  \n 5        1005       1987 Male       58   644. No      Yes            West     \n 6        1006       1994 Male      164   554. Yes     Yes            Midwest  \n 7        1007       1968 Male       39   608. No      No             Midwest  \n 8        1008       1994 Male       69   710. No      No             South    \n 9        1009       1958 Male      233   702. No      No             West     \n10        1010       1994 Female     77   605. Yes     No             Northeast\n# ℹ 10,521 more rows\n# ℹ 5 more variables: state <chr>, star_rating <dbl>, review_time <chr>,\n#   review_title <chr>, review_text <chr>\n```\n\n\n:::\n:::\n\n\n:::\n\n### Join data frames\n\nNote that missing values are identified as `NaN` or `null`. Series types include `str`, `bytes` (binary), `i64` (num), `bool`, and `int`.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nstore_transactions = pl.read_csv(os.path.join('data', 'store_transactions.csv'))\n\ncustomer_data.join(store_transactions, on='customer_id', how='left')\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10_531, 181)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>birth_year</th><th>gender</th><th>income</th><th>credit</th><th>married</th><th>college_degree</th><th>region</th><th>state</th><th>star_rating</th><th>review_time</th><th>review_title</th><th>review_text</th><th>jan_2005</th><th>feb_2005</th><th>mar_2005</th><th>apr_2005</th><th>may_2005</th><th>jun_2005</th><th>jul_2005</th><th>aug_2005</th><th>sep_2005</th><th>oct_2005</th><th>nov_2005</th><th>dec_2005</th><th>jan_2006</th><th>feb_2006</th><th>mar_2006</th><th>apr_2006</th><th>may_2006</th><th>jun_2006</th><th>jul_2006</th><th>aug_2006</th><th>sep_2006</th><th>oct_2006</th><th>nov_2006</th><th>dec_2006</th><th>&hellip;</th><th>dec_2015</th><th>jan_2016</th><th>feb_2016</th><th>mar_2016</th><th>apr_2016</th><th>may_2016</th><th>jun_2016</th><th>jul_2016</th><th>aug_2016</th><th>sep_2016</th><th>oct_2016</th><th>nov_2016</th><th>dec_2016</th><th>jan_2017</th><th>feb_2017</th><th>mar_2017</th><th>apr_2017</th><th>may_2017</th><th>jun_2017</th><th>jul_2017</th><th>aug_2017</th><th>sep_2017</th><th>oct_2017</th><th>nov_2017</th><th>dec_2017</th><th>jan_2018</th><th>feb_2018</th><th>mar_2018</th><th>apr_2018</th><th>may_2018</th><th>jun_2018</th><th>jul_2018</th><th>aug_2018</th><th>sep_2018</th><th>oct_2018</th><th>nov_2018</th><th>dec_2018</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>&hellip;</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1001</td><td>1971</td><td>&quot;Female&quot;</td><td>73000</td><td>742.082667</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;DC&quot;</td><td>4</td><td>&quot;06 11, 2015&quot;</td><td>&quot;Four Stars&quot;</td><td>&quot;everything&#x27;s fine&quot;</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>3</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td><td>3</td><td>5</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1002</td><td>1970</td><td>&quot;Female&quot;</td><td>31000</td><td>749.351433</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;West&quot;</td><td>&quot;WA&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td></tr><tr><td>1003</td><td>1988</td><td>&quot;Male&quot;</td><td>35000</td><td>542.239859</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;South&quot;</td><td>&quot;AR&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>4</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>4</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td></tr><tr><td>1004</td><td>1984</td><td>&quot;Other&quot;</td><td>64000</td><td>573.935783</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Midwest&quot;</td><td>&quot;MN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>4</td><td>0</td><td>&hellip;</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1005</td><td>1987</td><td>&quot;Male&quot;</td><td>58000</td><td>644.243856</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;HI&quot;</td><td>5</td><td>&quot;03 25, 2008&quot;</td><td>&quot;Great Product!!&quot;</td><td>&quot;I looked all over the Internet…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>5</td><td>0</td><td>3</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>0</td><td>1</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>11527</td><td>1982</td><td>&quot;Other&quot;</td><td>169000</td><td>603.366567</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;NY&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>5</td><td>0</td><td>5</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>4</td><td>0</td><td>&hellip;</td><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>3</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>0</td><td>2</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>4</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td></tr><tr><td>11528</td><td>1986</td><td>&quot;Female&quot;</td><td>24000</td><td>647.671383</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;RI&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>2</td><td>0</td><td>5</td><td>0</td><td>2</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>0</td><td>4</td><td>5</td></tr><tr><td>11529</td><td>1966</td><td>&quot;Female&quot;</td><td>112000</td><td>820.539578</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Northeast&quot;</td><td>&quot;NJ&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>1</td><td>0</td><td>3</td><td>5</td><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>5</td><td>3</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td></tr><tr><td>11530</td><td>1971</td><td>&quot;Male&quot;</td><td>234000</td><td>790.440173</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Midwest&quot;</td><td>&quot;OH&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>3</td><td>4</td><td>0</td><td>0</td><td>0</td><td>3</td><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>1</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>2</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>3</td></tr><tr><td>11531</td><td>1990</td><td>&quot;Male&quot;</td><td>160000</td><td>641.77857</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;West&quot;</td><td>&quot;MT&quot;</td><td>5</td><td>&quot;08 21, 2014&quot;</td><td>&quot;These are definitely one of th…</td><td>&quot;Husband really appreciates the…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>3</td><td>&hellip;</td><td>4</td><td>0</td><td>2</td><td>0</td><td>3</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstore_transactions <- read_csv(here::here(\"posts\", \"python-intro\", \"data\", \"store_transactions.csv\"))\n\nleft_join(customer_data, store_transactions, join_by(customer_id))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10,531 × 181\n   customer_id birth_year gender income credit married college_degree region   \n         <dbl>      <dbl> <chr>   <dbl>  <dbl> <chr>   <chr>          <chr>    \n 1        1001       1971 Female  73000   742. No      No             South    \n 2        1002       1970 Female  31000   749. Yes     No             West     \n 3        1003       1988 Male    35000   542. No      No             South    \n 4        1004       1984 Other   64000   574. Yes     Yes            Midwest  \n 5        1005       1987 Male    58000   644. No      Yes            West     \n 6        1006       1994 Male   164000   554. Yes     Yes            Midwest  \n 7        1007       1968 Male    39000   608. No      No             Midwest  \n 8        1008       1994 Male    69000   710. No      No             South    \n 9        1009       1958 Male   233000   702. No      No             West     \n10        1010       1994 Female  77000   605. Yes     No             Northeast\n# ℹ 10,521 more rows\n# ℹ 173 more variables: state <chr>, star_rating <dbl>, review_time <chr>,\n#   review_title <chr>, review_text <chr>, jan_2005 <dbl>, feb_2005 <dbl>,\n#   mar_2005 <dbl>, apr_2005 <dbl>, may_2005 <dbl>, jun_2005 <dbl>,\n#   jul_2005 <dbl>, aug_2005 <dbl>, sep_2005 <dbl>, oct_2005 <dbl>,\n#   nov_2005 <dbl>, dec_2005 <dbl>, jan_2006 <dbl>, feb_2006 <dbl>,\n#   mar_2006 <dbl>, apr_2006 <dbl>, may_2006 <dbl>, jun_2006 <dbl>, …\n```\n\n\n:::\n:::\n\n\n:::\n\n### Consecutive lines of code\n\nWhile possible with Python code generally, Polars embraces writing consecutive lines of code using *method chaining*, which is clearly akin to piping in R. Note that each line *starts* with `.` (rather than ending with `|>`) and the entire chain needs to be surrounded with `( )`.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(customer_data\n  .join(store_transactions, on='customer_id', how='left')\n  .filter(pl.col('region') == 'West', pl.col('feb_2005') == pl.col('feb_2005').max())\n  .with_columns(age = 2024 - pl.col('birth_year'))\n  .select(pl.col(['age', 'feb_2005']))\n  .sort(pl.col('age'), descending=True)\n  .slice(0, 1)\n)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>age</th><th>feb_2005</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>67</td><td>5</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  left_join(store_transactions, join_by(customer_id)) |> \n  filter(region == \"West\", feb_2005 == max(feb_2005)) |> \n  mutate(age = 2024 - birth_year) |> \n  select(age, feb_2005) |> \n  arrange(desc(age)) |> \n  slice(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n    age feb_2005\n  <dbl>    <dbl>\n1    67        5\n```\n\n\n:::\n:::\n\n\n:::\n\n### Summarize discrete data\n\nThe `.agg()` method stands for *aggregate*, which is exactly what `summarize()` does in R.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(customer_data\n  .group_by(pl.col(['region', 'college_degree']))\n  .agg(n = pl.len())\n)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (8, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>region</th><th>college_degree</th><th>n</th></tr><tr><td>str</td><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Midwest&quot;</td><td>&quot;Yes&quot;</td><td>872</td></tr><tr><td>&quot;West&quot;</td><td>&quot;Yes&quot;</td><td>4106</td></tr><tr><td>&quot;Northeast&quot;</td><td>&quot;No&quot;</td><td>640</td></tr><tr><td>&quot;West&quot;</td><td>&quot;No&quot;</td><td>989</td></tr><tr><td>&quot;Northeast&quot;</td><td>&quot;Yes&quot;</td><td>2584</td></tr><tr><td>&quot;South&quot;</td><td>&quot;Yes&quot;</td><td>220</td></tr><tr><td>&quot;Midwest&quot;</td><td>&quot;No&quot;</td><td>229</td></tr><tr><td>&quot;South&quot;</td><td>&quot;No&quot;</td><td>891</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  count(region, college_degree)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 3\n  region    college_degree     n\n  <chr>     <chr>          <int>\n1 Midwest   No               229\n2 Midwest   Yes              872\n3 Northeast No               640\n4 Northeast Yes             2584\n5 South     No               891\n6 South     Yes              220\n7 West      No               989\n8 West      Yes             4106\n```\n\n\n:::\n:::\n\n\n:::\n\n### Summarize continuous data\n\nThis is a good example of where object-oriented programming requires a different mindset. You might think that there is a general `mean()` function like in R, but there isn't and you'd have to load a specific library and reference its namespace to use such a function. Instead, `.mean()` here is a method for Polars Series and DataFrames.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(customer_data\n  .select(pl.col(['income', 'credit']))\n  .mean()\n)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>income</th><th>credit</th></tr><tr><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>138622.637926</td><td>667.160128</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |>\n  summarize(\n    avg_income = mean(income),\n    avg_credit = mean(credit)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  avg_income avg_credit\n       <dbl>      <dbl>\n1    138623.       667.\n```\n\n\n:::\n:::\n\n\n:::\n\n### Summarize discrete and continuous data\n\nCombining `.agg()` with `.group_by()` is similarly powerful as in {dplyr}.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(customer_data\n  .group_by(pl.col(['gender', 'region']))\n  .agg(\n    n = pl.len(), \n    avg_income = pl.col('income').mean(), \n    avg_credit = pl.col('credit').mean()\n  )\n  .sort(pl.col('avg_income'), descending=True)\n)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (12, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>gender</th><th>region</th><th>n</th><th>avg_income</th><th>avg_credit</th></tr><tr><td>str</td><td>str</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Other&quot;</td><td>&quot;Midwest&quot;</td><td>124</td><td>154637.096774</td><td>663.269593</td></tr><tr><td>&quot;Male&quot;</td><td>&quot;Midwest&quot;</td><td>420</td><td>152466.666667</td><td>666.03375</td></tr><tr><td>&quot;Other&quot;</td><td>&quot;Northeast&quot;</td><td>337</td><td>150563.79822</td><td>665.445377</td></tr><tr><td>&quot;Male&quot;</td><td>&quot;Northeast&quot;</td><td>1285</td><td>150498.054475</td><td>665.087794</td></tr><tr><td>&quot;Male&quot;</td><td>&quot;West&quot;</td><td>2079</td><td>149452.621453</td><td>666.591336</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Female&quot;</td><td>&quot;West&quot;</td><td>2497</td><td>133818.582299</td><td>668.158516</td></tr><tr><td>&quot;Female&quot;</td><td>&quot;Northeast&quot;</td><td>1602</td><td>133332.709114</td><td>669.02095</td></tr><tr><td>&quot;Other&quot;</td><td>&quot;South&quot;</td><td>118</td><td>119067.79661</td><td>659.819318</td></tr><tr><td>&quot;Male&quot;</td><td>&quot;South&quot;</td><td>430</td><td>117988.372093</td><td>669.075539</td></tr><tr><td>&quot;Female&quot;</td><td>&quot;South&quot;</td><td>563</td><td>105888.099467</td><td>663.69759</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |>\n  group_by(gender, region) |>\n  summarize(\n    n = n(),\n    avg_income = mean(income),\n    avg_credit = mean(credit)\n  ) |> \n  arrange(desc(avg_income))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'gender'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 × 5\n# Groups:   gender [3]\n   gender region        n avg_income avg_credit\n   <chr>  <chr>     <int>      <dbl>      <dbl>\n 1 Other  Midwest     124    154637.       663.\n 2 Male   Midwest     420    152467.       666.\n 3 Other  Northeast   337    150564.       665.\n 4 Male   Northeast  1285    150498.       665.\n 5 Male   West       2079    149453.       667.\n 6 Other  West        519    144420.       667.\n 7 Female Midwest     557    134083.       671.\n 8 Female West       2497    133819.       668.\n 9 Female Northeast  1602    133333.       669.\n10 Other  South       118    119068.       660.\n11 Male   South       430    117988.       669.\n12 Female South       563    105888.       664.\n```\n\n\n:::\n:::\n\n\n:::\n\n### Lazy evaluation\n\nRemember how Polars is incredibly fast? By tagging a data frame with `.lazy()`, we are asking Polars to not evaluate the code until triggered and to optimize the code for us in the underlying query engine. Before the code is triggered with something like `.collect()`, you can even see the underlying optimized query using `.explain()`.\n\nThis is exactly what happens when you use {dplyr} to connect to and communicate with a database using SQL code (except for the underlying query optimization).\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf = (customer_data\n  .group_by(pl.col(['gender', 'region']))\n  .agg(\n    n = pl.len(), \n    avg_income = pl.col('income').mean(), \n    avg_credit = pl.col('credit').mean()\n  )\n  .sort(pl.col('avg_income'), descending=True)\n).lazy()\n\ndf.explain()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'DF [\"gender\", \"region\", \"n\", \"avg_income\", ...]; PROJECT */5 COLUMNS'\n```\n\n\n:::\n\n```{.python .cell-code}\ndf.collect()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (12, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>gender</th><th>region</th><th>n</th><th>avg_income</th><th>avg_credit</th></tr><tr><td>str</td><td>str</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Other&quot;</td><td>&quot;Midwest&quot;</td><td>124</td><td>154637.096774</td><td>663.269593</td></tr><tr><td>&quot;Male&quot;</td><td>&quot;Midwest&quot;</td><td>420</td><td>152466.666667</td><td>666.03375</td></tr><tr><td>&quot;Other&quot;</td><td>&quot;Northeast&quot;</td><td>337</td><td>150563.79822</td><td>665.445377</td></tr><tr><td>&quot;Male&quot;</td><td>&quot;Northeast&quot;</td><td>1285</td><td>150498.054475</td><td>665.087794</td></tr><tr><td>&quot;Male&quot;</td><td>&quot;West&quot;</td><td>2079</td><td>149452.621453</td><td>666.591336</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Female&quot;</td><td>&quot;West&quot;</td><td>2497</td><td>133818.582299</td><td>668.158516</td></tr><tr><td>&quot;Female&quot;</td><td>&quot;Northeast&quot;</td><td>1602</td><td>133332.709114</td><td>669.02095</td></tr><tr><td>&quot;Other&quot;</td><td>&quot;South&quot;</td><td>118</td><td>119067.79661</td><td>659.819318</td></tr><tr><td>&quot;Male&quot;</td><td>&quot;South&quot;</td><td>430</td><td>117988.372093</td><td>669.075539</td></tr><tr><td>&quot;Female&quot;</td><td>&quot;South&quot;</td><td>563</td><td>105888.099467</td><td>663.69759</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_db <- customer_data |>\n  group_by(gender, region) |>\n  summarize(\n    n = n(),\n    avg_income = mean(income),\n    avg_credit = mean(credit)\n  ) |> \n  arrange(desc(avg_income))\n\ndata_db |> show_query()\n```\n:::\n\n\n\n```\n<SQL>\nSELECT\n    gender,\n    region,\n    COUNT(*) AS n,\n    AVG(income) AS avg_income,\n    AVG(credit) AS avg_credit\nFROM\n    customer_data\nGROUP BY\n    gender,\n    region\nORDER BY\n    avg_income DESC;\n```\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_db |> collect()\n```\n:::\n\n\n\n```\n`summarise()` has grouped output by 'gender'. You can override using the\n`.groups` argument.\n# A tibble: 12 × 5\n# Groups:   gender [3]\n   gender region        n avg_income avg_credit\n   <chr>  <chr>     <int>      <dbl>      <dbl>\n 1 Other  Midwest     124    154637.       663.\n 2 Male   Midwest     420    152467.       666.\n 3 Other  Northeast   337    150564.       665.\n 4 Male   Northeast  1285    150498.       665.\n 5 Male   West       2079    149453.       667.\n 6 Other  West        519    144420.       667.\n 7 Female Midwest     557    134083.       671.\n 8 Female West       2497    133819.       668.\n 9 Female Northeast  1602    133333.       669.\n10 Other  South       118    119068.       660.\n11 Male   South       430    117988.       669.\n12 Female South       563    105888.       664.\n```\n\n:::\n\n## Visualization\n\nThere's no way around it---visualizing data is where {ggplot2} simply reigns supreme, so much so that Posit has been investing in [plotnine](https://plotnine.org), a {ggplot2} port for Python. Maybe Posit will eventually facilitate a polyglot grammar of graphics, however in the spirit of this post, let's consider a genuinely \"Pythonic\" tool.\n\nIf NumPy is base R, [matplotlib](https://matplotlib.org) is plotting in base R. If that analogy holds, matplotlib is an acquired taste, so much so that [seaborn](https://seaborn.pydata.org) was developed to supplement matplotlib, much like pandas was developed to supplement NumPy. While we don't have a Polars-like replacement (come on Hadley, a polygplot {ggvis} is written in the stars!) we do have [seaborn.objects](https://seaborn.pydata.org/tutorial/objects_interface.html), a still-in-development module deliberately built with the consistency of the grammar of graphics in mind that also attempts to eliminate the need to invoke matplotlib for fine-tuning.\n\nAs a reminder, the grammar of graphics is a philosophical approach to visualizing data created by [Leland Wilkinson](https://link.springer.com/book/10.1007/0-387-28695-0) that inspired the creation of {ggplot2} and seaborn.objects. It's about composing a visualization a layer at a time, specifically:\n\n1. Data to visualize\n2. Mapping graphical elements to data\n3. A specific graphic representing the data and mappings\n4. Additional fine-tuning via facets, labels, scales, etc.\n\nHaving this principled approach to guide the development and consistency of a plotting approach is what distinguishes {ggplot2} and seaborn.objects. (I have often made the argument that SQL does something similar in providing a kind of grammar of data manipulation.) Let's illustrate some common visualizations using seaborn.objects and {ggplot2} and gain some intuition for how they are related and divergent.\n\n### Column plots\n\nOnce again, we see the use of an alias to shorten the namespace reference. Here, the alias convention for the seaborn.objects module is `so`. We also see one of the limitations of method chaining (and thus object-oriented programming): Methods are specific to objects defined by libraries. Thus we can't directly method chain data wrangled using Polars objects to be visualized by seaborn.objects like we can pipe data from {dplyr} to {ggplot2} in R.\n\nHowever, the plot itself starts with a familiar-looking `so.Plot()` function (seaborn-objects' version of `ggplot()`) which instantiates a Plot object and specifies (1) our data and (2) the mapping between that data and graphical elements. Then with a consistency that isn't present with {ggplot2} (I'm looking at you `|>` vs. `+`), there are a set of methods applicable to the Plot object, starting with `.add()`, that can be method chained. Finally the (3) specific graphic is created with another familiar-looking `so.Bar()`, which is a specific example of an object called a Mark (seaborn-objects' version of `geom_*()`).\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport seaborn.objects as so\n\nregion_count = (customer_data\n  .group_by(pl.col('region'))\n  .agg(n = pl.len())\n)\n\n(so.Plot(region_count, x = 'region', y = 'n')\n  .add(so.Bar())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  count(region) |> \n  ggplot(aes(x = region, y = n)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-29-3.png){width=672}\n:::\n:::\n\n\n:::\n\nIn certain instances we can have the necessary data wrangling done as part of the visualization. For example, in {ggplot2} we can call `geom_bar()` instead of `geom_col()` to produce the same plot while in seaborn.objects we still use the same Mark `so.Bar()` but add another object called a Stat---in this instance `so.Hist()` to produce the sum for us.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(so.Plot(customer_data, x = 'region')\n  .add(so.Bar(), so.Hist())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  ggplot(aes(x = region)) +\n  geom_bar()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-32-3.png){width=672}\n:::\n:::\n\n\n:::\n\nAnother Stat object is `so.Agg()`. We can join this with an object type called a Move to further customize our visualization---for example, using the Move object `so.Dodge()` to create a dodged column plot.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nregion_count = (customer_data\n  .group_by(pl.col(['region', 'college_degree']))\n  .agg(n = pl.len())\n)\n\n(so.Plot(region_count, x = 'region', y = 'n', color = 'college_degree')\n  .add(so.Bar(), so.Agg(), so.Dodge())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  count(region, college_degree) |> \n  ggplot(aes(x = region, y = n, fill = college_degree)) +\n  geom_col(position = \"dodge\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-35-3.png){width=672}\n:::\n:::\n\n\n:::\n\n### Histograms\n\nAccepting `so.Hist()` as a Stat and not a Mark, like it is in {ggplot2}, may seem awkward for the R user. However, what results in many specific geometries in {ggplot2} is reduced by the composibility of Mark, Stat, and Move objects in seaborn.objects. For example, a histogram also uses the `so.Hist()` Stat to bin data but uses the `so.Bars()` instead of `so.Bar()` to produce an actual histogram.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(so.Plot(customer_data, x = 'income', color = 'region')\n  .add(so.Bars(), so.Hist())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-37-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  ggplot(aes(x = income)) +\n  geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-38-3.png){width=672}\n:::\n:::\n\n\n:::\n\n### Scatterplots\n\nAgain we see the one-to-one correspondence of Mark objects and geometries, `so.Dot()` and `geom_point()`.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(so.Plot(customer_data, x = 'income', y = 'credit')\n  .add(so.Dot())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-40-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  ggplot(aes(x = income, y = credit)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-41-3.png){width=672}\n:::\n:::\n\n\n:::\n\nWe see again that a specialized geometry in {ggplot2} is composed of some combination of Mark, Stat, and Move (`so.Jitter()` is another Move object like `so.Dodge()`) objects in seaborn.objects, where there are parameters that can be further modified within each function call.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(so.Plot(customer_data, x = 'star_rating', y = 'income')\n  .add(so.Dot(pointsize = 10, alpha = 0.5), so.Jitter(0.75))\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-43-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  ggplot(aes(x = star_rating, y = income)) +\n  geom_jitter(size = 3, alpha = 0.5)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 7372 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-44-3.png){width=672}\n:::\n:::\n\n\n:::\n\n### Line plots\n\nIt's comforting to know that working with dates is just as problematic in Python as it is in R.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(so.Plot(customer_data, x = 'review_time', y = 'star_rating')\n  .add(so.Line())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-46-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  ggplot(aes(x = review_time, y = star_rating)) +\n  geom_line()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 7372 rows containing missing values or values outside the scale range\n(`geom_line()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-47-3.png){width=672}\n:::\n:::\n\n\n:::\n\nEven if we can't method chain between different object classes (including those from different libraries), we still need to rely on the back-and-forth between data wrangling and visualizing data.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nrating_data = (customer_data\n  .drop_nulls(pl.col('star_rating'))\n  .select(pl.col(['review_time', 'star_rating']))\n  .with_columns(\n    pl.col('review_time').str.to_date(format='%m %d, %Y').alias('review_time')\n  )\n  .with_columns(\n    pl.col('review_time').dt.year().alias('review_year')\n  )\n  .group_by('review_year')\n  .agg(pl.mean('star_rating').alias('avg_star_rating'))\n)\n\n(so.Plot(rating_data, x = 'review_year', y = 'avg_star_rating')\n  .add(so.Line())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-49-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  drop_na(star_rating) |> \n  select(review_time, star_rating) |> \n  mutate(\n    review_time = mdy(review_time),\n    review_year = year(review_time)\n  ) |> \n  group_by(review_year) |> \n  summarize(avg_star_rating = mean(star_rating)) |>\n  ggplot(aes(x = review_year, y = avg_star_rating)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-50-3.png){width=672}\n:::\n:::\n\n\n:::\n\n### Density plots\n\nInstead of a specific `geom_density()`, we compose it by combining `so.Area()` and `so.Hist()`.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(so.Plot(customer_data, x = 'income', color = 'gender')\n  .add(so.Area(), so.Hist())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-52-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  ggplot(aes(x = income, fill = gender)) +\n  geom_density(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-53-3.png){width=672}\n:::\n:::\n\n\n:::\n\n### Facets\n\nFinall, facets, like `.add()`, are a method for the Plot object.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nregion_count = (customer_data\n  .group_by(pl.col(['region', 'college_degree', 'gender']))\n  .agg(n = pl.len())\n)\n\n(so.Plot(region_count, x = 'region', y = 'n', color = 'college_degree')\n  .facet('gender')\n  .add(so.Bar(), so.Agg(), so.Dodge())\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-55-1.png){width=614}\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_data |> \n  count(region, college_degree, gender) |> \n  ggplot(aes(x = region, y = n, fill = college_degree)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ gender)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-56-3.png){width=672}\n:::\n:::\n\n\n:::\n\n## Modeling\n\nIf the adage is true that Python is \"the second best language for everything,\" it's machine learning that is arguably where it shines. If new statistical models first appear in R, then it can be said that the latest and greatest in machine learning and deep learning is incubated in Python and Python-adjacent libraries. At a high level, this should make sense. If R is tied closely to statistics, the big tent that is Python should naturally lend itself to the learning algorithms developed in computer science.\n\nThe most popular modeling library in Python is scikit-learn (referred to as sklearn in code). This machine learning library is built on NumPy, matplotlib, and SciPy---a library for scientific computing. The name scikit-learn comes from its origin as a \"scikit\" or \"SciPy Toolkit,\" a collection of extensions built for SciPy to provide specialized functions and methods.\n\nWhen it comes to modeling, R is equally diverse in its approaches. However, I am partial to the consistency of the {tidymodels} ecosystem of packages, which clearly draw inspiration from scikit-learn. Let's do a simple comparison of the two.\n\n### Prepare data\n\nWe'll start by specifying some parameter values and simulating data. Here we see the obsession with namespacing and efficiency on full display. In R, I load namespace-free access to *all* of the {tidyverse} functions with `library(tidyverse)`. In Python, sklearn is so large and has so many different modules that it is convention to load namespace-free access to *specific* functions and methods by importing them one at a time as in `from sklearn.linear_model import LinearRegression`.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import root_mean_squared_error\n\n# Set seed, variable, and parameter values.\nnp.random.seed(42)\nnobs = 500\nbeta0 = -5\nbeta1 = 5\nbeta2 = 2\nbeta3 = 0\n\n# Simulate data.\nsim_data = pl.DataFrame({\n    'x1': np.round(np.random.uniform(0, 20, nobs)),\n    'x2': np.random.choice(['level01', 'level02', 'level03'], nobs, p = [0.7, 0.2, 0.1]),\n    'y': beta0 + beta1 * np.random.uniform(0, 20, nobs) + beta2 * (np.random.choice(['level01', 'level02', 'level03'], nobs, p=[0.7, 0.2, 0.1]) == 'level02') + beta3 * (np.random.choice(['level01', 'level02', 'level03'], nobs, p=[0.7, 0.2, 0.1]) == 'level03') + np.random.normal(0, 3, nobs)\n})\n\nsim_data\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (500, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x1</th><th>x2</th><th>y</th></tr><tr><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>7.0</td><td>&quot;level01&quot;</td><td>15.07666</td></tr><tr><td>19.0</td><td>&quot;level01&quot;</td><td>51.125741</td></tr><tr><td>15.0</td><td>&quot;level01&quot;</td><td>83.961397</td></tr><tr><td>12.0</td><td>&quot;level02&quot;</td><td>68.491231</td></tr><tr><td>3.0</td><td>&quot;level01&quot;</td><td>75.0641</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>7.0</td><td>&quot;level01&quot;</td><td>62.539493</td></tr><tr><td>12.0</td><td>&quot;level03&quot;</td><td>58.44809</td></tr><tr><td>2.0</td><td>&quot;level01&quot;</td><td>42.765411</td></tr><tr><td>19.0</td><td>&quot;level03&quot;</td><td>33.206444</td></tr><tr><td>20.0</td><td>&quot;level01&quot;</td><td>83.561412</td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n\n# Set seed, variable, and parameter values.\nset.seed(42)\nnobs <- 500\nbeta0 <- -5\nbeta1 <- 5\nbeta2 <- 2\nbeta3 <- 0\n\n# Simulate data.\nsim_data <- tibble(\n  x1 = round(runif(nobs, min = 0, max = 20)),\n  x2 = rbinom(nobs, size = 2, prob = c(0.7, 0.3)) |> \n    as.factor() |> fct_recode(\"level01\" = \"0\", \"level02\" = \"1\", \"level03\" = \"2\"),\n  y = beta0 + beta1 * x1 + beta2 * ifelse(x2 == \"level02\", 1, 0) + beta3 * ifelse(x2 == \"level03\", 1, 0) + rnorm(nobs, mean = 0, sd = 3)\n)\n\nsim_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 × 3\n      x1 x2          y\n   <dbl> <fct>   <dbl>\n 1    18 level03 88.1 \n 2    19 level01 92.7 \n 3     6 level02 27.0 \n 4    17 level02 82.4 \n 5    13 level03 57.8 \n 6    10 level02 46.4 \n 7    15 level02 68.9 \n 8     3 level01  7.10\n 9    13 level02 58.3 \n10    14 level01 67.5 \n# ℹ 490 more rows\n```\n\n\n:::\n:::\n\n\n:::\n\nHere we can see that scikit-learn requires pandas DataFrames. We also see an interesting reversal where splitting the data into training and testing data produces separate datasets in Python while R creates a single object that contains both.\n\nFor feature engineering, recipe steps in {tidymodels} mirror specific transformers in scikit-learn.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Training and testing split.\nX = sim_data.drop('y').to_pandas()\ny = sim_data['y'].to_pandas()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# Feature engineering.\ncategorical_features = ['x2']\ncategorical_transformer = Pipeline(steps=[\n  ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n  transformers=[\n      ('cat', categorical_transformer, categorical_features)\n  ]\n)\n```\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Training and testing split.\nsim_split <- initial_split(sim_data, prop = 0.90)\n\n# Feature engineering.\nsim_recipe <- training(sim_split) |>\n  recipe(y ~ .) |> \n  step_dummy(all_nominal_predictors())\n```\n:::\n\n\n:::\n\n### Specify and fit a model\n\nHere we can see some equivalence between scikit-learn's Pipelines and {tidymodels}' workflows where both feature engineering and model fitting are composed and executed at once.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Model specification.\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', LinearRegression())\n])\n\n# Fit the model.\nmodel.fit(X_train, y_train)\n```\n:::\n\n\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model specification.\nsim_lm <- linear_reg() |> \n  set_engine(\"lm\")\n\n# Compose a workflow.\nsim_wf_lm <- workflow() |> \n  add_recipe(sim_recipe) |> \n  add_model(sim_lm)\n\n# Fit the model.\nsim_lm_fit <- fit(sim_wf_lm, data = training(sim_split))\n```\n:::\n\n\n:::\n\n### Evaluate model fit\n\nIt's in evaluating model fit that differences are most apparent. While both scikit-learn and {tidymodels} can compute predictive fit values, scikit-learn doesn't have a built-in way to access or visualize parameter estimates, especially interval estimates. At some level this shouldn't be surprising given the different mindsets, but it is still a bit jarring that the most popular modeling package in Python can do prediction but not (statistical) inference. There are other libraries, of course. The [statsmodels](https://www.statsmodels.org/) library is {stats}-like, including formula notation. The [Bambi](https://bambinos.github.io/bambi/) library is Python's version of {brms} for Bayesian modeling.\n\n::: {.panel-tabset}\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Compute RMSE.\ny_pred = model.predict(X_test)\nroot_mean_squared_error(y_test, y_pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n30.556378031804933\n```\n\n\n:::\n:::\n\n\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize slope parameter estimates.\ntidy(sim_lm_fit, conf.int = TRUE) |> \n  ggplot(aes(x = term)) + \n  geom_point(aes(y = estimate)) + \n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .1) +\n  geom_hline(yintercept = 0, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-65-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Compute RMSE.\nsim_lm_fit |> \n  predict(new_data = testing(sim_split)) |>\n  bind_cols(testing(sim_split)) |>\n  rmse(truth = y, estimate = .pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        3.16\n```\n\n\n:::\n:::\n\n\n:::\n\n## Communication\n\nWhen it comes to communication, the elephant in the room is Jupyter notebooks. Even though Jupyter was designed to be polyglot (Julia, Python, and R), it really is the domain of Python. As an R user, Jupyter is *weird*. It appears that Jupyter is what happens when you don't have a great IDE to work with---IDE functionality gets absorbed into the document type itself (e.g., an embedded kernel selector). But just because you *can* use Jupyter notebooks doesn't mean you *should*.\n\nIt shouldn't be surprising that I recommend [Quarto](https://quarto.org) for communication. It's plain text (so it plays well with version control), supports Python and R natively with code cells that behave like actual scripts, and is designed as a means to whatever document type you need---PDFs, slides, websites, dashboards, etc. That said, if you really love or are required to work with Jupyter notebooks, Quarto can convert any `.ipynb` into a `.qmd` via the command line with `quarto convert notebook.ipynb` as well as render any `.ipynb` into whatever document type you need using `quarto render notebook.ipynb --to format`.\n\n## Final thoughts\n\nThere's honestly a lot to love about both Python and R. Don't be afraid to use the best of both interchangeably. I've found it's easiest to switch between the different mindsets by keeping some syntax differences. For example, in R I use double quotes and in Python I use single quotes.\n\nIf I could change one thing about Python it would be for the community to embrace the fact that it was named after Monty Python, not a snake. Like R has Peanuts references for each release, here's hoping we eventually see a stable Python release code-named \"It's Just a Flesh Wound.\"\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}